{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Face/Emotion Detection using Integrated Webcam</b>\n",
    "\n",
    "This program will use OpenCV, a trained face detection model in Caffe, and a custom Keras model for emotion recognition. Both models are pretrained. The face detection does a great job while the custom Keras model has a mediocre performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Step 1:</b><br/>\n",
    "Import required libraries. This includes OpenCV, numpy and os. Keras layers are imported later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 2:</b><br/>\n",
    "Read the caffe model and wieghts, both located in a subfolder named \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "base_dir = os.getcwd()\n",
    "prototxt_path = os.path.join(base_dir + '/model/deploy.prototxt')\n",
    "caffemodel_path = os.path.join(base_dir + '/model/weights.caffemodel')\n",
    "\n",
    "# Read the model\n",
    "model = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 3:</b><br/>\n",
    "Keras libraries and model are defined here. It includes 4 2D convolution layers; then, the model weights are loaded. <br/> <b> Note that </b>Since face detection model exist, classification model is called \"model1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\razali\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\razali\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\razali\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\razali\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\razali\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\razali\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\razali\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:64: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\razali\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:497: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\razali\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\razali\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\razali\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\razali\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\razali\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\razali\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\razali\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3636: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\razali\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3464: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\razali\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\razali\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1264: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\razali\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:159: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\razali\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:167: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "# Create the model\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "model1.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(1024, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(7, activation='softmax'))\n",
    "\n",
    "#Load the model weights\n",
    "model1.load_weights(base_dir + '/model/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 4:</b><br/>\n",
    "The keras model is defined to categorize facial emotions into seven categories. These categories are defined in a dictionary which assigns them a label (alphabetical order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 5:</b><br/>\n",
    "In the final step, OpenCV is used to read a video from the webcam, using VideoCaptured. <br/>\n",
    "<span style=\"color:#FF0000\">The first step</span> in processing the video stream is mean subtraction and scaling. This has been done using <b><i>blobFromImage</b></i> function in OpenCV. The argument it takes are shown in the code. Scale factor of 0 is used and swapRB is false. Note that OpenCV reads BGR colorful images and swapRB converts them to RGB.<br/>\n",
    "<span style=\"color:#0000ff\">The second step</span> is to use the processed image as an input image for trained face detection model. Then loop on the function (since performed on a live feed) and when probability of a face being in an image is more than 0.5 show the bounding box.\n",
    "\n",
    "<span style=\"color:#006a4e\">In the third and last step</span> use the detected face as an input for emotion classifier, convert it to 48 by 48 (size of the input for model1), predict the emotion and put it as a text on the detected frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To capture video from webcam. \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# To use a video file as input \n",
    "# cap = cv2.VideoCapture('filename.mp4')\n",
    "\n",
    "cv2.startWindowThread()\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Read the frame\n",
    "        _, img = cap.read()\n",
    "\n",
    "        #Preprocess the image, subtract mean and convert BGR to RGB\n",
    "        (h, w) = img.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(image = cv2.resize(img, (300, 300)), \\\n",
    "                                     scalefactor = 1.0, size = (300, 300), \\\n",
    "                                     mean = (104.0, 177.0, 123.0), swapRB=True)\n",
    "        #Use the blob as an input to the face detection model\n",
    "        model.setInput(blob)\n",
    "        detections = model.forward()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Create frame around face\n",
    "\n",
    "        for i in range(0, detections.shape[2]):\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "\n",
    "          # If confidence > 0.5, show box around face\n",
    "            if (confidence > 0.5):\n",
    "                cv2.rectangle(img, (startX, startY), (endX, endY), (255, 255, 255), 2)\n",
    "\n",
    "                frame = img[startY:endY, startX:endX]\n",
    "\n",
    "\n",
    "                #Colorful image is converted to grayscale just for the classification step (emotion detection)\n",
    "                frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                #The input size of the classifier is 48 by 48 as it converted to 48 by 48\n",
    "                cropped_img = np.expand_dims(np.expand_dims(cv2.resize(frame_gray, (48, 48)), -1), 0)\n",
    "                prediction = model1.predict(cropped_img)\n",
    "\n",
    "                #Select the category with the maximum probability that came from the softmax layer(prediction)\n",
    "                maxindex = int(np.argmax(prediction))\n",
    "\n",
    "                #Putting text on the frame to show result of the classification\n",
    "                cv2.putText(img, emotion_dict[maxindex], (startX, startY), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                #Resize the frame to show\n",
    "                resized = cv2.resize(img, (1280, 960), interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "                #Show the live feed on screen\n",
    "                cv2.imshow('Live', resized)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "            break\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "        \n",
    "cv2.destroyWindow('Live')\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
